{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up runtime environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at stanford-crfm/music-medium-800k were not used when initializing GPT2LMHeadModel: ['token_out_embeddings']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import sys,time\n",
    "\n",
    "import midi2audio\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "from anticipation import ops\n",
    "from anticipation.sample import generate\n",
    "from anticipation.tokenize import extract_instruments\n",
    "from anticipation.convert import events_to_midi,midi_to_events\n",
    "from anticipation.visuals import visualize\n",
    "from anticipation.config import *\n",
    "from anticipation.vocab import *\n",
    "\n",
    "\n",
    "SMALL_MODEL = 'stanford-crfm/music-small-800k'     # faster inference, worse sample quality\n",
    "MEDIUM_MODEL = 'stanford-crfm/music-medium-800k'   # slower inference, better sample quality\n",
    "LARGE_MODEL = 'stanford-crfm/music-large-800k'     # slowest inference, best sample quality\n",
    "\n",
    "# load an anticipatory music transformer\n",
    "model = AutoModelForCausalLM.from_pretrained(MEDIUM_MODEL).cuda()\n",
    "\n",
    "# a MIDI synthesizer\n",
    "fs = midi2audio.FluidSynth('/usr/share/sounds/sf2/FluidR3_GM.sf2')\n",
    "\n",
    "# the MIDI synthesis script\n",
    "def synthesize(fs, tokens):\n",
    "    mid = events_to_midi(tokens)\n",
    "    mid.save('tmp.mid')\n",
    "    fs.midi_to_audio('tmp.mid', 'tmp.wav')\n",
    "    return 'tmp.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unconditional Generation\n",
    "Call generate function with start_time=0 and end_time=10, asking the model to generate 10 seconds of music starting from time 0. The top_p nucleus sampling parameter controls how conservative sampling will be: lower values will tend to promote more boring, repetitive generation whereas higher values might encourage the model to be too experimental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 10\n",
    "unconditional_tokens = generate(model, start_time=0, end_time=length, top_p=0.98)\n",
    "Audio(synthesize(fs, unconditional_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIDI Continuation\n",
    "load a midi file and clip it to the first ~5 seconds then have the model continue it.\n",
    "\n",
    "first pick a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36fc1711791b4c15b7f3a902b2e79e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/mnt/c/Users/Ian/GitHub/anticipation', filename='', title='', show_hidden=False, select_descâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and display a FileChooser widget\n",
    "fc = FileChooser('/mnt/c/Users/Ian/GitHub/anticipation')  # Adjust the path to where your MIDI files are located, remembering WSL path conventions\n",
    "fc.filter_pattern = '*.mid'\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected file: /mnt/c/Users/Ian/GitHub/anticipation/MIDI/31b.mid\n",
      "FluidSynth runtime version 2.2.5\n",
      "Copyright (C) 2000-2022 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of Creative Technology Ltd.\n",
      "\n",
      "Rendering audio to file 'tmp.wav'..\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     segment \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mclip(events, \u001b[38;5;241m41\u001b[39m, \u001b[38;5;241m41\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m     10\u001b[0m     segment \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mtranslate(segment, \u001b[38;5;241m-\u001b[39mops\u001b[38;5;241m.\u001b[39mmin_time(segment, seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m---> 11\u001b[0m     Audio(\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file selected.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m, in \u001b[0;36msynthesize\u001b[0;34m(fs, tokens)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msynthesize\u001b[39m(fs, tokens):\n\u001b[0;32m---> 32\u001b[0m     mid \u001b[38;5;241m=\u001b[39m \u001b[43mevents_to_midi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     mid\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmp.mid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m     fs\u001b[38;5;241m.\u001b[39mmidi_to_audio(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmp.mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmp.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/Users/Ian/GitHub/anticipation/anticipation/convert.py:339\u001b[0m, in \u001b[0;36mevents_to_midi\u001b[0;34m(tokens, debug)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevents_to_midi\u001b[39m(tokens, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m compound_to_midi(\u001b[43mevents_to_compound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m, debug\u001b[38;5;241m=\u001b[39mdebug)\n",
      "File \u001b[0;32m/mnt/c/Users/Ian/GitHub/anticipation/anticipation/convert.py:330\u001b[0m, in \u001b[0;36mevents_to_compound\u001b[0;34m(tokens, debug)\u001b[0m\n\u001b[1;32m    327\u001b[0m out[\u001b[38;5;241m3\u001b[39m::\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m=\u001b[39m [tok\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m tokens[\u001b[38;5;241m2\u001b[39m::\u001b[38;5;241m3\u001b[39m]]\n\u001b[1;32m    328\u001b[0m out[\u001b[38;5;241m4\u001b[39m::\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(tokens)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m*\u001b[39m[\u001b[38;5;241m72\u001b[39m] \u001b[38;5;66;03m# default velocity\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m MAX_DUR\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(out[\u001b[38;5;241m2\u001b[39m::\u001b[38;5;241m5\u001b[39m]) \u001b[38;5;241m<\u001b[39m MAX_PITCH\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(out[\u001b[38;5;241m3\u001b[39m::\u001b[38;5;241m5\u001b[39m]) \u001b[38;5;241m<\u001b[39m MAX_INSTR\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# Check if a file is selected\n",
    "if fc.selected is not None:\n",
    "    selected_path = fc.selected\n",
    "    print(f\"Selected file: {selected_path}\")\n",
    "    \n",
    "    events = midi_to_events(selected_path)\n",
    "    Audio(synthesize(fs, ops.clip(events, 0, 30)))\n",
    "\n",
    "    segment = ops.clip(events, 0, 0+16)\n",
    "    segment = ops.translate(segment, -ops.min_time(segment, seconds=False))\n",
    "    Audio(synthesize(fs, segment))\n",
    "else:\n",
    "    print(\"No file selected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anticipation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
